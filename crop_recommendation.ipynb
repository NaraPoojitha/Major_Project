{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "33hUoxV9WLz6"
      },
      "outputs": [],
      "source": [
        "# importing necessary libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the dataset\n",
        "\n",
        "df = pd.read_csv(\"Crop_recommendation.csv\")\n"
      ],
      "metadata": {
        "id": "N7zE6-7EYfYk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Exploration of Dataset\n",
        "\n",
        "df.head()\n",
        "df.info()\n",
        "df.describe()\n"
      ],
      "metadata": {
        "id": "OwPhaE_jYhXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the number of unique crop types\n",
        "print('Number of Crop types:', df['label'].nunique())\n",
        "\n",
        "# Extract the labels from the DataFrame\n",
        "labels_df = df['label']\n",
        "\n",
        "# Count the occurrences of each label\n",
        "crops_labels = pd.DataFrame(labels_df.value_counts())\n",
        "\n",
        "# Sort the DataFrame by index (label)\n",
        "crops_labels.sort_index(inplace=True)\n",
        "\n",
        "# Reset the index to make 'label' a regular column\n",
        "crops_labels.reset_index(inplace=True)\n",
        "\n",
        "# Rename the columns for clarity\n",
        "crops_labels.rename(columns={'index':'label', 'label':'count'}, inplace=True)\n",
        "\n",
        "# Set the name of the index column\n",
        "crops_labels.index.name = 'index'\n",
        "\n",
        "# Print the DataFrame with explanations\n",
        "print(crops_labels)"
      ],
      "metadata": {
        "id": "b_DhzFWvY2kQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (15,5))\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "sns.histplot(df['N'],color = 'blue', kde = True)\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "sns.histplot(df['P'],color = 'red', kde = True)\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "sns.histplot(df['K'],color = 'green', kde = True)"
      ],
      "metadata": {
        "id": "aRN0PLJPZQki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (15,8))\n",
        "\n",
        "plt.subplot(2,2,1)\n",
        "sns.histplot(df['ph'],color = 'blue', kde = True)\n",
        "\n",
        "plt.subplot(2,2,2)\n",
        "sns.histplot(df['temperature'],color = 'red', kde = True)\n",
        "\n",
        "plt.subplot(2,2,3)\n",
        "sns.histplot(df['humidity'],color = 'purple', kde = True)\n",
        "\n",
        "plt.subplot(2,2,4)\n",
        "sns.histplot(df['rainfall'],color = 'green', kde = True)\n"
      ],
      "metadata": {
        "id": "s8LsMSJqZmWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the pivot table\n",
        "crop_desc = pd.pivot_table(df, index='label', aggfunc='mean')\n",
        "\n",
        "# Reset the index to make 'label' a regular column\n",
        "crop_desc.reset_index(inplace=True)\n",
        "\n",
        "# Print the pivot table\n",
        "print(crop_desc)"
      ],
      "metadata": {
        "id": "xJKJcMqkZnMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = crop_desc['label'].unique()\n",
        "\n",
        "n_value = crop_desc['N']\n",
        "p_value = crop_desc['P']\n",
        "k_value = crop_desc['K']\n",
        "\n",
        "x = np.arange(len(labels))\n",
        "width = 0.2\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(1,1, figsize = (17,7))\n",
        "n_bar = ax.bar(x - width, n_value, width, label='N')\n",
        "p_bar = ax.bar(x, p_value, width, label='P')\n",
        "k_bar = ax.bar(x + width, k_value, width, label='K')\n",
        "\n",
        "\n",
        "ax.set_ylabel('kg/ha (Mean)')\n",
        "ax.set_title('NPK Means by Crop')\n",
        "ax.set_xticks(x, labels, rotation = 45)\n",
        "ax.legend()\n",
        "\n",
        "ax.bar_label(n_bar, padding=3,label_type='edge',fmt = '%.f')\n",
        "ax.bar_label(p_bar, padding=3, label_type='edge',fmt = '%.f')\n",
        "ax.bar_label(k_bar, padding=3, label_type='edge',fmt = '%.f')\n",
        "\n",
        "fig.tight_layout()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hAmxF3EBZw0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(18, 5))\n",
        "ph_boxplot = sns.boxplot(data = df, x = 'label', y = 'ph')\n",
        "ph_boxplot.set_xlabel('Crop',fontsize = 14)\n",
        "ph_boxplot.set_ylabel('pH', fontsize = 14)\n",
        "ph_boxplot.axes.set_title('Boxplot - pH by Crop', fontsize=14)\n",
        "\n",
        "ph_boxplot.set_xticklabels(ax.get_xticklabels(),rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sRNGA74YZ5dU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "# Checking missing values of the dataset in each column\n",
        "df.isnull().sum()\n"
      ],
      "metadata": {
        "id": "ajyAa-uvZ9uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Define updated thresholds for temperature, humidity, and rainfall for each season\n",
        "spring_threshold = {'temperature': (10, 35), 'humidity': (5, 80), 'rainfall': (40, 200)}\n",
        "summer_threshold = {'temperature': (30, 45), 'humidity': (40, 80), 'rainfall': (0, 120)}\n",
        "monsoon_threshold = {'temperature': (20, 38), 'humidity': (55, 95), 'rainfall': (100, 5000)}\n",
        "autumn_threshold = {'temperature': (20, 35), 'humidity': (30, 95), 'rainfall': (25, 900)}\n",
        "winter_threshold = {'temperature': (5, 30), 'humidity': (30, 90), 'rainfall': (0, 700)}\n",
        "\n",
        "# Function to classify each data point into a season\n",
        "def classify_season(row):\n",
        "    temp, hum, rain = row['temperature'], row['humidity'], row['rainfall']\n",
        "    if spring_threshold['temperature'][0] <= temp <= spring_threshold['temperature'][1] \\\n",
        "        and spring_threshold['humidity'][0] <= hum <= spring_threshold['humidity'][1] \\\n",
        "        and spring_threshold['rainfall'][0] <= rain <= spring_threshold['rainfall'][1]:\n",
        "        return 'Spring'\n",
        "    elif summer_threshold['temperature'][0] <= temp <= summer_threshold['temperature'][1] \\\n",
        "        and summer_threshold['humidity'][0] <= hum <= summer_threshold['humidity'][1] \\\n",
        "        and summer_threshold['rainfall'][0] <= rain <= summer_threshold['rainfall'][1]:\n",
        "        return 'Summer'\n",
        "    elif monsoon_threshold['temperature'][0] <= temp <= monsoon_threshold['temperature'][1] \\\n",
        "        and monsoon_threshold['humidity'][0] <= hum <= monsoon_threshold['humidity'][1] \\\n",
        "        and monsoon_threshold['rainfall'][0] <= rain <= monsoon_threshold['rainfall'][1]:\n",
        "        return 'Monsoon'\n",
        "    elif autumn_threshold['temperature'][0] <= temp <= autumn_threshold['temperature'][1] \\\n",
        "        and autumn_threshold['humidity'][0] <= hum <= autumn_threshold['humidity'][1] \\\n",
        "        and autumn_threshold['rainfall'][0] <= rain <= autumn_threshold['rainfall'][1]:\n",
        "        return 'Autumn'\n",
        "    elif winter_threshold['temperature'][0] <= temp <= winter_threshold['temperature'][1] \\\n",
        "        and winter_threshold['humidity'][0] <= hum <= winter_threshold['humidity'][1] \\\n",
        "        and winter_threshold['rainfall'][0] <= rain <= winter_threshold['rainfall'][1]:\n",
        "        return 'Winter'\n",
        "    else:\n",
        "        return 'Monsoon'\n",
        "        print(temp,hum,rain)\n",
        "\n",
        "# Apply the function to classify each data point\n",
        "df['season'] = df.apply(classify_season, axis=1)\n",
        "\n",
        "df = df[['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall', 'season', 'label']]\n",
        "\n",
        "# Save the classified data to a new CSV file\n",
        "df.to_csv('Crop_recommendation_with_season.csv', index=False)\n"
      ],
      "metadata": {
        "id": "4TJWNd4OamRk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the classified data\n",
        "classified_data = pd.read_csv('Crop_recommendation_with_season.csv')\n",
        "\n",
        "# Initialize LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit and transform the 'season' column to numerical labels\n",
        "classified_data['season'] = label_encoder.fit_transform(classified_data['season'])\n",
        "\n",
        "# Display the mapping between original labels and numerical labels\n",
        "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
        "print(\"Label Mapping:\", label_mapping)\n",
        "\n",
        "# Save the updated data with numerical labels to the same CSV file\n",
        "classified_data.to_csv('Crop_recommendation_with_season_labels.csv', index=False)\n",
        "\n",
        "#Label Mapping: {'Autumn': 0, 'Monsoon': 1, 'Spring': 2, 'Summer': 3, 'Winter': 4}"
      ],
      "metadata": {
        "id": "XZfEuqGXafT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_csv('Crop_recommendation_with_season_labels.csv')\n",
        "X = df1.drop('label', axis = 1)\n",
        "y = df1['label']"
      ],
      "metadata": {
        "id": "RtQE3Ol0jzXq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification Models\n",
        "\n",
        "# Decision Tree\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import metrics\n",
        "\n",
        "#Data Splitting:\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=3)\n",
        "\n",
        "#Defines a dictionary containing the parameters to be tuned (criterion and max_depth) and their respective values.\n",
        "param_dict = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22],\n",
        "    'random_state': [2]\n",
        "}\n",
        "\n",
        "#Creating a Base Decision Tree Model:\n",
        "test_dec_tree = DecisionTreeClassifier(random_state=2)\n",
        "test_dec_tree.fit(X_train, y_train)\n",
        "\n",
        "#performing hyperparameter tuning for a Decision Tree classifier using GridSearchCV\n",
        "grid = GridSearchCV(test_dec_tree, param_dict, cv=5, n_jobs=-1, verbose=3)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(grid.best_params_)\n",
        "print(grid.best_score_)\n",
        "\n"
      ],
      "metadata": {
        "id": "ZxSQFHwXjYmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training a Decision Tree classifier with specified hyperparameters\n",
        "#and evaluating its performance on the training and testing datasets\n",
        "\n",
        "#Creating Decision Tree Classifier:\n",
        "\n",
        "Dec_tree = DecisionTreeClassifier(max_depth=8, criterion='entropy', random_state=2)\n",
        "\n",
        "#Fitting the Model:\n",
        "Dec_tree.fit(X_train, y_train)\n",
        "\n",
        "dt_train_score = Dec_tree.score(X_train, y_train)\n",
        "print(f'Decision Tree Train Accuracy is: {dt_train_score:.4f}')\n",
        "\n",
        "dt_predicted_values = Dec_tree.predict(X_test)\n",
        "dt_test_score = metrics.accuracy_score(y_test, dt_predicted_values)\n",
        "print(f'Decision Tree Test Accuracy is: {dt_test_score:.4f}')\n",
        "\n",
        "dt_report = classification_report(y_test, dt_predicted_values, digits=4)\n",
        "print(dt_report)\n"
      ],
      "metadata": {
        "id": "PfTz7FKTk4lr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Generating a heatmap to visualize the confusion matrix of the Decision Tree classifier's predictions on the test data\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#Computing the Confusion Matrix:\n",
        "cm_dt = confusion_matrix(y_test, dt_predicted_values)\n",
        "#Creating the Heatmap:\n",
        "f, ax = plt.subplots(figsize=(10, 7))\n",
        "sns.heatmap(cm_dt, annot=True, linewidth=0.5, fmt=\".0f\", cmap='crest', ax=ax)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title('Predicted vs actual')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "M7U2e0JqlYE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest\n",
        "\n",
        "# RandomForestClassifier with GridSearchCV for hyperparameter tuning\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "#Initializing and Fitting the RandomForestClassifier:\n",
        "test_rdf_clf = RandomForestClassifier(random_state=2)\n",
        "test_rdf_clf.fit(X_train, y_train)\n",
        "#Defining Hyperparameters for GridSearchCV:\n",
        "param_dict = {\n",
        "    'n_estimators': [50, 100, 150, 200],\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22],\n",
        "    'random_state': [2]\n",
        "}\n",
        "#Performing GridSearchCV:\n",
        "grid = GridSearchCV(test_rdf_clf, param_dict, cv=5, n_jobs=-1, verbose=3)\n",
        "grid.fit(X_train, y_train)\n",
        "print(grid.best_params_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1oa8ZItlxqx",
        "outputId": "6910ddf7-956a-44d5-942c-e973f7d7d28b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 88 candidates, totalling 440 fits\n",
            "{'criterion': 'gini', 'max_depth': 18, 'n_estimators': 100, 'random_state': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Initializing and Fitting the RandomForestClassifier:\n",
        "\n",
        "rdf_clf = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=18, random_state=2)\n",
        "rdf_clf.fit(X_train, y_train)\n",
        "rdf_train_score = rdf_clf.score(X_train, y_train)\n",
        "print(f'Random Forest Train Accuracy is: {rdf_train_score:.4f}')\n",
        "rdf_predicted_values = rdf_clf.predict(X_test)\n",
        "rdf_test_score = metrics.accuracy_score(y_test, rdf_predicted_values)\n",
        "print(f'Random Forest Test Accuracy is: {rdf_test_score:.4f}')\n",
        "rdf_report = classification_report(y_test, rdf_predicted_values, digits=4)\n",
        "print(rdf_report)\n"
      ],
      "metadata": {
        "id": "izaHB4oDmUxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#confusion matrix for the RandomForestClassifier's predictions on the test set\n",
        "cm_rdf = confusion_matrix(y_test,rdf_predicted_values)\n",
        "\n",
        "f, ax = plt.subplots(figsize=(10,7))\n",
        "sns.heatmap(cm_rdf, annot=True, linewidth=0.5, fmt=\".0f\",  cmap='crest', ax = ax)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title('Predicted vs actual')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rNt-JZCWm1FY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#K-Nearest Neighbors\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "#preprocessing the features by scaling them using StandardScaler and then transforming both the training and test sets\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_train_scaled = sc.fit_transform(X_train)\n",
        "X_test_scaled = sc.transform(X_test)\n"
      ],
      "metadata": {
        "id": "IA7y4eb4m8uS"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Iterating over different values of n_neighbors for the K-nearest neighbors classifier\n",
        "\n",
        "score_list = []\n",
        "for i in range(4, 20):\n",
        "    knn = KNeighborsClassifier(n_neighbors=i)\n",
        "    knn.fit(X_train_scaled, y_train)\n",
        "\n",
        "    knn_train_score = knn.score(X_train_scaled, y_train)\n",
        "\n",
        "    knn_predicted_values = knn.predict(X_test_scaled)\n",
        "    knn_test_score = metrics.accuracy_score(y_test, knn_predicted_values)\n",
        "\n",
        "    score_list.append((i, knn_train_score, knn_test_score))\n",
        "    score_knn_df = pd.DataFrame(score_list, columns=['k', 'Train Score', 'Test Score'])\n",
        "print(score_knn_df)"
      ],
      "metadata": {
        "id": "lQlE-IH4nSl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training the K-nearest neighbors classifier:\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train_scaled, y_train)\n",
        "\n",
        "knn_train_score = knn.score(X_train_scaled, y_train)\n",
        "print(f'K-Nearest Neighbors Train Accuracy is : {knn_train_score :.4f}')\n",
        "\n",
        "knn_predicted_values = knn.predict(X_test_scaled)\n",
        "knn_test_score = metrics.accuracy_score(y_test, knn_predicted_values)\n",
        "print(f'K-Nearest Neighbors Test Accuracy is : {knn_test_score :.4f}')\n",
        "\n",
        "knn_report = classification_report(y_test, knn_predicted_values, digits=4)\n",
        "print(knn_report)\n"
      ],
      "metadata": {
        "id": "BuWwE09TnkYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#confusion matrix for the predictions made by the K-nearest neighbors classifier on the test set\n",
        "cm_knn = confusion_matrix(y_test,knn_predicted_values)\n",
        "\n",
        "f, ax = plt.subplots(figsize=(10,7))\n",
        "sns.heatmap(cm_knn, annot=True, linewidth=0.5, fmt=\".0f\",  cmap='crest', ax = ax)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title('Predicted vs actual')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RRauSRYxn0__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Exporting Random Forest Model\n",
        "\n",
        "from joblib import Parallel, delayed\n",
        "import joblib\n",
        "\n",
        "final_rdf_clf = RandomForestClassifier(n_estimators = 100, criterion = 'gini', max_depth = 18, random_state = 2)\n",
        "final_rdf_clf.fit(X,y)\n",
        "\n",
        "joblib.dump(final_rdf_clf, 'crop_rdf_clf.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VY7Lx2dMoD-v",
        "outputId": "946315a7-04c8-40f8-aca6-ca3e624d91c4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['crop_rdf_clf.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ]
}