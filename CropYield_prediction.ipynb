{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "33hUoxV9WLz6"
      },
      "outputs": [],
      "source": [
        "# importing necessary libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the dataset\n",
        "\n",
        "df = pd.read_csv(\"/content/crop_production.csv\")\n"
      ],
      "metadata": {
        "id": "N7zE6-7EYfYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Exploration of Dataset\n",
        "\n",
        "df.head()\n",
        "df.info()\n",
        "df.describe()\n"
      ],
      "metadata": {
        "id": "OwPhaE_jYhXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check the unique values in dataset\n",
        "df.apply(lambda x: len(x.unique()))\n",
        "# check for categorical attributes\n",
        "cat_col = []\n",
        "for x in df.dtypes.index:\n",
        "    if df.dtypes[x] == 'object':\n",
        "        cat_col.append(x)\n",
        "cat_col"
      ],
      "metadata": {
        "id": "b_DhzFWvY2kQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print the categorical columns\n",
        "for col in cat_col:\n",
        "    print(col)\n",
        "    print(df[col].value_counts())\n",
        "    print()"
      ],
      "metadata": {
        "id": "Q8wj1ZiUUd0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the figure size\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Plot histogram for Area\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.histplot(df['Area'], color='blue', kde=True)\n",
        "plt.title('Area Distribution')\n",
        "plt.xlabel('Area')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "# Plot histogram for Production\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.histplot(df['Production'], color='red', kde=True)\n",
        "plt.title('Production Distribution')\n",
        "plt.xlabel('Production')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aRN0PLJPZQki"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a scatter plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(df['Crop_Year'], df['Production'], color='red', alpha=0.5)\n",
        "plt.title('Production Over Years')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Production')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "s8LsMSJqZmWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#it show the count of each crop type\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.countplot(x='Crop', data = df)"
      ],
      "metadata": {
        "id": "xJKJcMqkZnMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "# Checking missing values of the dataset in each column\n",
        "df.isnull().sum()\n"
      ],
      "metadata": {
        "id": "ajyAa-uvZ9uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping missing values\n",
        "df = df.dropna()\n",
        "# Checking missing values of the dataset in each column\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "09EpEBNbcSio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding a new column Yield which indicates Production per unit Area.\n",
        "\n",
        "df['Yield'] = (df['Production'] / df['Area'])\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "gABRszxNce-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importing label encoder for converting categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Initialize LabelEncoders for 'District_Name', 'Crop', and 'Season'\n",
        "district_encoder = LabelEncoder()\n",
        "crop_encoder = LabelEncoder()\n",
        "season_encoder = LabelEncoder()\n",
        "\n",
        "# Encode 'District_Name', 'Crop', and 'Season' columns\n",
        "df['State'] = district_encoder.fit_transform(df['State_Name'])\n",
        "df['District'] = district_encoder.fit_transform(df['District_Name'])\n",
        "df['crop'] = crop_encoder.fit_transform(df['Crop'])\n",
        "df['season'] = season_encoder.fit_transform(df['Season'])\n",
        "\n",
        "# Drop the original categorical columns\n",
        "df.drop(['State_Name','District_Name', 'Crop', 'Season'], axis=1, inplace=True)\n",
        "data = df\n",
        "\n",
        "# Display the encoded dataset\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "4TJWNd4OamRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#correlation heatmap\n",
        "plt.figure(figsize=[10,8])\n",
        "sns.heatmap(df.corr(),annot=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BueId4XOWGjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X = data.drop([\"Production\",\"Yield\"], axis=1)\n",
        "y = data[\"Production\"]\n",
        "\n"
      ],
      "metadata": {
        "id": "RtQE3Ol0jzXq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification Models\n",
        "\n",
        "#Decision Tree\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "# Data Splitting\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.01, random_state=3)\n",
        "\n",
        "# Define a dictionary containing the parameters to be tuned and their respective values\n",
        "param_dict = {\n",
        "    'criterion': ['friedman_mse', 'squared_error', 'poisson', 'absolute_error'],\n",
        "    'max_depth': [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22],\n",
        "    'random_state': [2]\n",
        "}\n",
        "\n",
        "# Create a Base Decision Tree Model\n",
        "test_dec_tree = DecisionTreeRegressor(random_state=2)\n",
        "test_dec_tree.fit(X_train, y_train)\n",
        "\n",
        "# Performing hyperparameter tuning for the DecisionTreeRegressor using GridSearchCV\n",
        "grid = GridSearchCV(test_dec_tree, param_dict, cv=2, n_jobs=-1, verbose=3)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(grid.best_params_)\n",
        "print(grid.best_score_)\n",
        "\n",
        "# Output the best parameters and best score\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZxSQFHwXjYmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Training a DecisionTreeRegressor with specified hyperparameters\n",
        "# and evaluating its performance on the training and testing datasets\n",
        "\n",
        "# Creating DecisionTreeRegressor\n",
        "Dec_tree = DecisionTreeRegressor(max_depth=8, criterion='poisson', random_state=2)\n",
        "\n",
        "# Fitting the Model:\n",
        "Dec_tree.fit(X_train, y_train)\n",
        "\n",
        "# Evaluating on training data\n",
        "dt_train_predicted_values = Dec_tree.predict(X_train)\n",
        "dt_train_mse = mean_squared_error(y_train, dt_train_predicted_values)\n",
        "dt_train_r2 = r2_score(y_train, dt_train_predicted_values)\n",
        "print(f'Decision Tree Train MSE: {dt_train_mse:.4f}')\n",
        "print(f'Decision Tree Train R2 Score: {dt_train_r2:.4f}')\n",
        "\n",
        "# Evaluating on testing data\n",
        "dt_test_predicted_values = Dec_tree.predict(X_test)\n",
        "dt_test_mse = mean_squared_error(y_test, dt_test_predicted_values)\n",
        "dt_test_r2 = r2_score(y_test, dt_test_predicted_values)\n",
        "print(f'Decision Tree Test MSE: {dt_test_mse:.4f}')\n",
        "print(f'Decision Tree Test R2 Score: {dt_test_r2:.4f}')\n"
      ],
      "metadata": {
        "id": "PfTz7FKTk4lr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcc61b3d-81a1-4e92-d745-dbe4917b3a1a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Train MSE: 18610902052310.1602\n",
            "Decision Tree Train R2 Score: 0.9366\n",
            "Decision Tree Test MSE: 25020956658256.1797\n",
            "Decision Tree Test R2 Score: 0.6722\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting actual vs predicted values\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.scatter(y_test, dt_test_predicted_values, color='blue')\n",
        "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--')\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Actual vs Predicted Values (DecisionTreeRegressor)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "M7U2e0JqlYE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest\n",
        "\n",
        "# RandomForestRegressor with GridSearchCV for hyperparameter tuning\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "#Initializing and Fitting the RandomForestRegressor:\n",
        "test_rdf_clf = RandomForestRegressor(random_state=2)\n",
        "test_rdf_clf.fit(X_train, y_train)\n",
        "#Defining Hyperparameters for GridSearchCV:\n",
        "param_dict = {\n",
        "    'n_estimators': [50, 100, 150, 200],\n",
        "    'criterion':['friedman_mse', 'squared_error', 'poisson', 'absolute_error'],\n",
        "    'max_depth': [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22],\n",
        "    'random_state': [2]\n",
        "}\n",
        "#Performing GridSearchCV:\n",
        "grid = GridSearchCV(test_rdf_clf, param_dict, cv=2, n_jobs=-1, verbose=3)\n",
        "grid.fit(X_train, y_train)\n",
        "print(grid.best_params_)\n"
      ],
      "metadata": {
        "id": "x1oa8ZItlxqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initializing and Fitting the RandomForestRegressor:\n",
        "\n",
        "rdf_clf = RandomForestRegressor(n_estimators=50, criterion='poisson', max_depth=8, random_state=2)\n",
        "rdf_clf.fit(X_train, y_train)\n",
        "rdf_train_score = rdf_clf.score(X_train, y_train)\n",
        "print(f'Random Forest Train Accuracy is: {rdf_train_score:.4f}')\n",
        "rdf_predicted_values = rdf_clf.predict(X_test)\n",
        "rdf_test_score = metrics.accuracy_score(y_test, rdf_predicted_values)\n",
        "print(f'Random Forest Test Accuracy is: {rdf_test_score:.4f}')\n",
        "rdf_report = mean_squared_error(y_test, rdf_predicted_values)\n",
        "print(rdf_report)\n"
      ],
      "metadata": {
        "id": "izaHB4oDmUxq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "1145b149-9bba-43b6-f791-cf50482be52b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Train Accuracy is: 0.9573\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "continuous is not supported",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-165474d43185>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Random Forest Train Accuracy is: {rdf_train_score:.4f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mrdf_predicted_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdf_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mrdf_test_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrdf_predicted_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Random Forest Test Accuracy is: {rdf_test_score:.4f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mrdf_report\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrdf_predicted_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m                     )\n\u001b[1;32m    212\u001b[0m                 ):\n\u001b[0;32m--> 213\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multilabel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;31m# No metrics support \"multiclass-multioutput\" format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multilabel-indicator\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: continuous is not supported"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting actual vs predicted values\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.scatter(y_test, dt_test_predicted_values, color='blue')\n",
        "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--')\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Actual vs Predicted Values (RandomForestRegressor)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "rNt-JZCWm1FY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Exporting Random Forest Model\n",
        "\n",
        "from joblib import Parallel, delayed\n",
        "import joblib\n",
        "\n",
        "final_rdf_clf = RandomForestRegressor(n_estimators=50, criterion='poisson', max_depth=8, random_state=2)\n",
        "final_rdf_clf.fit(X,y)\n",
        "\n",
        "joblib.dump(final_rdf_clf, 'yield_rdf_clf.pkl')"
      ],
      "metadata": {
        "id": "VY7Lx2dMoD-v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}